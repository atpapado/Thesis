{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for **super-resolution** (figures $1$ and $5$ from main paper).. Change `factor` to $8$ to reproduce images from fig. $9$ from supmat.\n",
    "\n",
    "You can play with parameters and see how they affect the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "*Uncomment if running on colab* \n",
    "Set Runtime -> Change runtime type -> Under Hardware Accelerator select GPU in Google Colab \n",
    "\"\"\"\n",
    "# !git clone https://github.com/DmitryUlyanov/deep-image-prior\n",
    "# !mv deep-image-prior/* ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from time import time \n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from models import *\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from my_utils import * \n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from models.downsampler import Downsampler\n",
    "from datetime import datetime\n",
    "\n",
    "import shutil \n",
    "from utils.sr_utils import *\n",
    "import PIL\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "imsize = -1 \n",
    "enforse_div32 = 'CROP' # we usually need the dimensions to be divisible by a power of two (32 in this case)\n",
    "PLOT = True\n",
    "im_res = '20m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image and baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts here - Read all images in path and save them in dictionary indexed by image resolution(10m,20m,30m)\n",
    "Data_Path = '/home/savvas/Thesis/Data/Sentinel-2_Images_Testing/'\n",
    "imgs_sentinel = get_data2(Data_Path,imgs=True,paths_to_imgs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define closure and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    global i, net_input\n",
    "    \n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "\n",
    "    out_HR = net(net_input)\n",
    "    out_LR = downsampler(out_HR)\n",
    "    \n",
    "    total_loss = mse(out_LR, img_LR_var) \n",
    "    \n",
    "    if tv_weight > 0:\n",
    "        total_loss += tv_weight * tv_loss(out_HR)\n",
    "        \n",
    "    total_loss.backward()\n",
    "\n",
    "    # Log\n",
    "    psnr_LR = peak_signal_noise_ratio(torch_to_np(img_LR_var), torch_to_np(out_LR))\n",
    "#     psnr_HR = peak_signal_noise_ratio(test_image, torch_to_np(out_HR))\n",
    "#     psnr_HR =35.0\n",
    "    print ('Iteration %05d    PSNR_LR %.3f   MSE %.8f' % (i, psnr_LR,total_loss), '\\r', end='')\n",
    "                      \n",
    "    # History\n",
    "#     psnr_history.append([psnr_LR, psnr_HR])\n",
    "    tmp = beautify(better_test_image).astype(np.float32)/255.\n",
    "    if PLOT and i % 500 == 0:\n",
    "        out_HR_np = beautify(torch_to_np(out_HR)).astype(np.float32)/255.\n",
    "        \n",
    "        if im_res == '10m' :\n",
    "            f,(ax1,ax2) = plt.subplots(ncols=2,figsize=(60,60))\n",
    "            ax1.imshow(tmp.transpose(1,2,0)[:,:,:3])\n",
    "            ax1.set_title('Original Image ',fontsize=40)\n",
    "            ax2.imshow(out_HR_np.transpose(1,2,0)[:,:,:3])\n",
    "            ax2.set_title('SR Image ',fontsize=40)\n",
    "            plt.show()\n",
    "\n",
    "# FOR 20m IMAGES\n",
    "        elif im_res == '20m' :\n",
    "            f,(ax1,ax2,ax3,ax4) = plt.subplots(ncols=4,figsize=(30,30))\n",
    "            ax1.imshow(tmp.transpose(1,2,0)[:,:,3:])\n",
    "            ax1.set_title('Original Image Last 3 Channels',fontsize=20)\n",
    "            ax2.imshow(out_HR_np.transpose(1,2,0)[:,:,3:])\n",
    "            ax2.set_title('SR Last 3 Channels',fontsize=20)\n",
    "            ax3.imshow(tmp.transpose(1,2,0)[:,:,:3])\n",
    "            ax3.set_title('Original Image First 3 Channels',fontsize=20)\n",
    "            ax4.imshow(out_HR_np.transpose(1,2,0)[:,:,:3])\n",
    "            ax4.set_title('SR First 3 Channels',fontsize=20)\n",
    "            plt.show()\n",
    "\n",
    "# FOR 60m IMAGEs\n",
    "        else :\n",
    "            f,(ax1,ax2,ax3,ax4) = plt.subplots(ncols=4,figsize=(30,30))\n",
    "            ax1.imshow(tmp[0],cmap='gray')\n",
    "            ax1.set_title('Original Image First Channel',fontsize=20)\n",
    "            ax2.imshow(out_HR_np[0],cmap='gray')\n",
    "            ax2.set_title('SR Firt Channel',fontsize=20)\n",
    "            ax3.imshow(tmp[1],cmap='gray')\n",
    "            ax3.set_title('Original Image Last Channel',fontsize=20)\n",
    "            ax4.imshow(out_HR_np[1],cmap='gray')\n",
    "            ax4.set_title('SR Last Channel',fontsize=20)\n",
    "            plt.show()\n",
    "#         plot_image_grid([test_image[:3], np.clip(out_HR_np[:3], 0, 1)], factor=13, nrow=3)\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "    return total_loss,out_HR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part is for super resolving on single image !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up parameters and net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_test_image = imgs_sentinel[im_res][2]\n",
    "input_depth = 32\n",
    "channels = better_test_image.shape[0]\n",
    "\n",
    "INPUT =     'noise'\n",
    "pad   =     'reflection'\n",
    "OPT_OVER =  'net'\n",
    "KERNEL_TYPE='lanczos2'\n",
    "\n",
    "LR = 0.01\n",
    "tv_weight = 0.0\n",
    "\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "factor = 2 # 8\n",
    "if factor == 4: \n",
    "    num_iter = 8000\n",
    "    reg_noise_std = 0.03\n",
    "elif factor == 8:\n",
    "    num_iter = 8000\n",
    "    reg_noise_std = 0.02\n",
    "elif factor == 2:\n",
    "    num_iter = 8000\n",
    "    reg_noise_std = 0.01\n",
    "elif factor == 6:\n",
    "    num_iter = 8000\n",
    "    reg_noise_std = 0.02\n",
    "else:\n",
    "    assert False, 'We did not experiment with other factors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_input = get_noise(input_depth, INPUT, (better_test_image.shape[1]*factor, better_test_image.shape[2]*factor)).type(dtype).detach()\n",
    "# NET_TYPE = 'ResNet'\n",
    "NET_TYPE = 'skip'\n",
    "# NET_TYPE = 'UNet'\n",
    "\n",
    "net = get_net(input_depth, NET_TYPE, pad,\n",
    "              n_channels=channels,\n",
    "              skip_n33d=128, \n",
    "              skip_n33u=128, \n",
    "              skip_n11=4, \n",
    "              num_scales=5,\n",
    "              upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "# Losses\n",
    "mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "img_LR_var = np_to_torch(better_test_image).type(dtype)\n",
    "\n",
    "downsampler = Downsampler(n_planes=channels, factor=factor, kernel_type=KERNEL_TYPE, phase=0.5, preserve_size=True).type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "psnr_history = [] \n",
    "net_input_saved = net_input.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "\n",
    "i = 0\n",
    "p = get_params(OPT_OVER, net, net_input)\n",
    "stop_epoch,best_result=optimize(OPTIMIZER, p, closure, LR, num_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part is for super resolving every image in every resolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_test_image = imgs_sentinel[im_res][2]\n",
    "input_depth = 32\n",
    "channels = better_test_image.shape[0]\n",
    "\n",
    "INPUT =     'noise'\n",
    "pad   =     'reflection'\n",
    "OPT_OVER =  'net'\n",
    "KERNEL_TYPE='lanczos2'\n",
    "\n",
    "LR = 0.01\n",
    "tv_weight = 0.0\n",
    "\n",
    "OPTIMIZER = 'adam'\n",
    "def set_params(imres):\n",
    "    if imres == '10m' :\n",
    "        factor = 6 \n",
    "    elif imres == '20m':\n",
    "        factor = 6\n",
    "    else :\n",
    "        factor = 6\n",
    "    \n",
    "    if factor == 4: \n",
    "        num_iter = 8000\n",
    "        reg_noise_std = 0.03\n",
    "    elif factor == 8:\n",
    "        num_iter = 8000\n",
    "        reg_noise_std = 0.05\n",
    "    elif factor == 2:\n",
    "        num_iter = 8000\n",
    "        reg_noise_std = 0.02\n",
    "    elif factor == 6:\n",
    "        num_iter = 8000\n",
    "        reg_noise_std = 0.05\n",
    "        \n",
    "    return factor, num_iter,reg_noise_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_name=create_folder(factor,'/home/savvas/Thesis/Results/DIP/').split('/')[-1]\n",
    "for im_res in ['10m','20m','60m']:\n",
    "    factor, num_iter,reg_noise_std = set_params(im_res)\n",
    "    for num,image in enumerate(imgs_sentinel[im_res]):\n",
    "        # Create directoty to save results\n",
    "        if not os.path.isdir(f'/home/savvas/Thesis/Results/DIP/{folder_name}/{im_res}/'):\n",
    "            os.mkdir(f'/home/savvas/Thesis/Results/DIP/{folder_name}/{im_res}/')\n",
    "   \n",
    "        print('#'*50,f' Image {num+1} ','#'*50)\n",
    "        #Get image and its channels\n",
    "        better_test_image = image\n",
    "        channels = better_test_image.shape[0]\n",
    "        #Get Patches\n",
    "        if im_res == '10m':\n",
    "            if factor == 2:\n",
    "                patches = get_subimages(better_test_image,2)\n",
    "            elif factor == 4 :\n",
    "                patches = get_subimages(better_test_image,3)\n",
    "            elif factor == 6 :\n",
    "                patches = get_subimages(better_test_image,5)\n",
    "            for index, img in enumerate(patches):\n",
    "                print('#'*50,f' Image{num+1} Patch {index+1} ','#'*50)\n",
    "                better_test_image = img\n",
    "                #Initialize Net\n",
    "                net_input = get_noise(input_depth, INPUT, (better_test_image.shape[1]*factor, better_test_image.shape[2]*factor)).type(dtype).detach()\n",
    "                print('Initialize Network')\n",
    "                \n",
    "                NET_TYPE = 'skip'\n",
    "              \n",
    "                net = get_net(input_depth, NET_TYPE, pad,\n",
    "                              n_channels=channels,\n",
    "                              skip_n33d=128, \n",
    "                              skip_n33u=128, \n",
    "                              skip_n11=4, \n",
    "                              num_scales=5,\n",
    "                              upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "                # Losses\n",
    "                mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "                img_LR_var = np_to_torch(better_test_image).type(dtype)\n",
    "\n",
    "                downsampler = Downsampler(n_planes=channels, factor=factor, kernel_type=KERNEL_TYPE, phase=0.5, preserve_size=True).type(dtype)\n",
    "\n",
    "                #Train\n",
    "                start_time = time()\n",
    "                print('Starting Trainning')\n",
    "                net_input_saved = net_input.detach().clone()\n",
    "                noise = net_input.detach().clone()\n",
    "\n",
    "                i = 0\n",
    "                p = get_params(OPT_OVER, net, net_input)\n",
    "                stop_epoch,best_result=optimize(OPTIMIZER, p, closure, LR, num_iter)\n",
    "\n",
    "                print('Finished Trainning...')\n",
    "                print(f'Training took {(time()-start_time)/60} minutes')\n",
    "\n",
    "                SR = torch_to_np(best_result)\n",
    "                save_image(SR,SR.shape[0],'/home/savvas/Thesis/Results/DIP/{}/{}/image_{}_patch_{}_x{}_{}_epochs'.format(folder_name,im_res,num+1,index+1,factor,stop_epoch))\n",
    "                print('Patch Saved')\n",
    "\n",
    "            full_image = reconstruct_image(path_to_patches=f'/home/savvas/Thesis/Results/DIP/{folder_name}/{im_res}/',image_num=num+1)\n",
    "            save_image(full_image,full_image.shape[0],f'/home/savvas/Thesis/Results/DIP/{folder_name}/{im_res}/image_{num+1}_x{factor}')\n",
    "            break\n",
    "        elif im_res == '20m':\n",
    "            if factor == 2:\n",
    "                patches = get_subimages(better_test_image,1)\n",
    "            elif factor == 4 :\n",
    "                patches = get_subimages(better_test_image,2)\n",
    "            elif factor == 6 :\n",
    "                patches = get_subimages(better_test_image,3)\n",
    "            for index, img in enumerate(patches):\n",
    "                print('#'*50,f' Image{num+1} Patch {index+1} ','#'*50)\n",
    "                better_test_image = img\n",
    "                #Initialize Net\n",
    "                net_input = get_noise(input_depth, INPUT, (better_test_image.shape[1]*factor, better_test_image.shape[2]*factor)).type(dtype).detach()\n",
    "                print('Initialize Network')\n",
    "                \n",
    "                NET_TYPE = 'skip'\n",
    "              \n",
    "                net = get_net(input_depth, NET_TYPE, pad,\n",
    "                              n_channels=channels,\n",
    "                              skip_n33d=128, \n",
    "                              skip_n33u=128, \n",
    "                              skip_n11=4, \n",
    "                              num_scales=5,\n",
    "                              upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "                # Losses\n",
    "                mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "                img_LR_var = np_to_torch(better_test_image).type(dtype)\n",
    "\n",
    "                downsampler = Downsampler(n_planes=channels, factor=factor, kernel_type=KERNEL_TYPE, phase=0.5, preserve_size=True).type(dtype)\n",
    "\n",
    "                #Train\n",
    "                start_time = time()\n",
    "                print('Starting Trainning')\n",
    "                net_input_saved = net_input.detach().clone()\n",
    "                noise = net_input.detach().clone()\n",
    "\n",
    "                i = 0\n",
    "                p = get_params(OPT_OVER, net, net_input)\n",
    "                stop_epoch,best_result=optimize(OPTIMIZER, p, closure, LR, num_iter)\n",
    "\n",
    "                print('Finished Trainning...')\n",
    "                print(f'Training took {(time()-start_time)/60} minutes')\n",
    "\n",
    "                SR = torch_to_np(best_result)\n",
    "                save_image(SR,SR.shape[0],'/home/savvas/Thesis/Results/DIP/{}/{}/image_{}_patch_{}_x{}_{}_epochs'.format(folder_name,im_res,num+1,index+1,factor,stop_epoch))\n",
    "                print('Patch Saved')\n",
    "\n",
    "            if factor>2:\n",
    "                full_image = reconstruct_image(path_to_patches=f'/home/savvas/Thesis/Results/DIP/{folder_name}/{im_res}/',image_num=num+1)\n",
    "                save_image(full_image,full_image.shape[0],f'/home/savvas/Thesis/Results/DIP/{folder_name}/{im_res}/image_{num+1}_x{factor}')\n",
    "            break\n",
    "        else :\n",
    "            #Initialize Net\n",
    "            net_input = get_noise(input_depth, INPUT, (better_test_image.shape[1]*factor, better_test_image.shape[2]*factor)).type(dtype).detach()\n",
    "            print('Initialize Network')\n",
    "            NET_TYPE = 'skip'\n",
    "\n",
    "            net = get_net(input_depth, NET_TYPE, pad,\n",
    "                          n_channels=channels,\n",
    "                          skip_n33d=128, \n",
    "                          skip_n33u=128, \n",
    "                          skip_n11=4, \n",
    "                          num_scales=5,\n",
    "                          upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "            # Losses\n",
    "            mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "            img_LR_var = np_to_torch(better_test_image).type(dtype)\n",
    "\n",
    "            downsampler = Downsampler(n_planes=channels, factor=factor, kernel_type=KERNEL_TYPE, phase=0.5, preserve_size=True).type(dtype)\n",
    "\n",
    "            #Train\n",
    "            start_time = time()\n",
    "            print('Starting Trainning')\n",
    "            net_input_saved = net_input.detach().clone()\n",
    "            noise = net_input.detach().clone()\n",
    "\n",
    "            i = 0\n",
    "            p = get_params(OPT_OVER, net, net_input)\n",
    "            stop_epoch,best_result = optimize(OPTIMIZER, p, closure, LR, num_iter)\n",
    "\n",
    "            print('Finished Trainning...')\n",
    "            print(f'Training took {(time()-start_time)/60} minutes')\n",
    "            SR = torch_to_np(best_result)\n",
    "            save_image(SR,SR.shape[0],'/home/savvas/Thesis/Results/DIP/{}/{}/image_{}_x{}_{}_epochs'.format(folder_name,im_res,num+1,factor,stop_epoch))\n",
    "            print('Image Saved')\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
